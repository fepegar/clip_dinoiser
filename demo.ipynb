{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0017a479-b454-4843-9c47-3c4fd0d298b2",
   "metadata": {},
   "source": [
    "# CLIP-DINOiser visualization demo üñºÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88be8f-847e-427d-bdcb-0db278337535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from models.builder import build_model\n",
    "from helpers.visualization import mask2rgb\n",
    "from segmentation.datasets import PascalVOCDataset\n",
    "from hydra import compose, initialize\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms as T\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "initialize(config_path=\"configs\", version_base=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cd90c-cc3e-43a5-99e1-fa3ea666d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_per_image(file_path, text_prompts, palette, model, *, use_dino):\n",
    "    assert os.path.isfile(file_path), f\"No such file: {file_path}\"\n",
    "\n",
    "    img = Image.open(file_path).convert('RGB')\n",
    "    img_tens = T.PILToTensor()(img).unsqueeze(0).to(device) / 255.\n",
    "\n",
    "    h, w = img_tens.shape[-2:]\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tens, use_dino=use_dino).cpu()\n",
    "    output = F.interpolate(\n",
    "        output,\n",
    "        scale_factor=model.vit_patch_size,\n",
    "        mode=\"bilinear\",\n",
    "        align_corners=False,\n",
    "    )[..., :h, :w]\n",
    "    output = output[0].argmax(dim=0)\n",
    "    mask = mask2rgb(output, palette)\n",
    "\n",
    "    fig = plt.figure(figsize=(3, 1))\n",
    "    classes = np.unique(output).tolist()\n",
    "    plt.imshow(np.array(itemgetter(*classes)(PALETTE)).reshape(1, -1, 3))\n",
    "    plt.xticks(np.arange(len(classes)), list(itemgetter(*classes)(text_prompts)), rotation=45)\n",
    "    plt.yticks([])\n",
    "\n",
    "    return mask, fig, img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0107d95-1244-4d43-8428-ac031fa5a728",
   "metadata": {},
   "source": [
    "### Load and configure a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f904d10-fdf9-47f5-8053-2aeb871f8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_path = './checkpoints/last.pt'\n",
    "check = torch.load(check_path, map_location='cpu')\n",
    "dinoclip_cfg = \"clip_dinoiser.yaml\"\n",
    "cfg = compose(config_name=dinoclip_cfg)\n",
    "dict(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c477e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "model = build_model(cfg.model, class_names=PascalVOCDataset.CLASSES).to(device)\n",
    "model.clip_backbone.decode_head.use_templates=False # switching off the imagenet templates for fast inference\n",
    "model.load_state_dict(check['model_state_dict'], strict=False)\n",
    "model = model.eval()\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfa0596-1312-4865-bad8-9b06337513a3",
   "metadata": {},
   "source": [
    "### Example with 'background' class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ceb49-72c0-4475-baf2-b6a278a1a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'assets/vintage_bike.jpeg'\n",
    "PALETTE = [(0, 0, 0), (156, 143, 189), (79, 158, 101)]\n",
    "\n",
    "# specify your prompts\n",
    "TEXT_PROMPTS = ['background', 'vintage bike', 'leather bag']\n",
    "model.clip_backbone.decode_head.update_vocab(TEXT_PROMPTS)\n",
    "model.to(device)\n",
    "\n",
    "# set apply FOUND (background detector) to True\n",
    "model.apply_found = True\n",
    "\n",
    "# run segmentation\n",
    "for use_dino in [False, True]:\n",
    "    print(f\"Using DINO: {use_dino}\")\n",
    "    mask, ticks, img = visualize_per_image(file, TEXT_PROMPTS, PALETTE, model, use_dino=use_dino)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "    alpha=0.5\n",
    "    blend = (alpha)*np.array(img)/255. + (1-alpha) * mask/255.\n",
    "    ax[0].imshow(blend)\n",
    "    ax[1].imshow(mask)\n",
    "    ax[0].axis('off')\n",
    "    ax[1].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0200f3c5-9dd2-4bef-ab41-e3847bf73a3d",
   "metadata": {},
   "source": [
    "### Example without 'background' class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a1aeb-a14b-4733-a9e9-a3fe29def88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'assets/rusted_van.png'\n",
    "\n",
    "PALETTE = [[25, 29, 136], [128, 112, 112], [85, 124, 85], [250, 112, 112], [250, 250, 0], [250, 0, 0]]\n",
    "\n",
    "# specify TEXT PROMPTS\n",
    "TEXT_PROMPTS = [\"rusted van\", \"green trees\", \"foggy clouds\", \"mountains\", \"dog\"]\n",
    "model.clip_backbone.decode_head.update_vocab(TEXT_PROMPTS)\n",
    "model.to(device)\n",
    "\n",
    "# specify whether applying FOUND or not\n",
    "model.apply_found = False\n",
    "\n",
    "for use_dino in [False, True]:\n",
    "    print(f\"Using DINO: {use_dino}\")\n",
    "    mask, ticks, img = visualize_per_image(file, TEXT_PROMPTS, PALETTE, model, use_dino=use_dino)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "    alpha=0.5\n",
    "    blend = (alpha)*np.array(img)/255. + (1-alpha)*mask/255.\n",
    "    ax[0].imshow(blend)\n",
    "    ax[1].imshow(mask)\n",
    "    ax[0].axis('off')\n",
    "    ax[1].axis('off')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
